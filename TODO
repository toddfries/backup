- sanity checking of syntax, i.e. invalid typical things:
  sshdump://host/ (no user present)
  dump://user@host/ (user present)
- separate uncomp data vs uncomp speed units. example:
   02/06/2008 13:51:08 CST uncomp. 271.98GB vs comp. 260.63GB
   02/06/2008 13:51:08 CST uncomp. 0.00GB/s vs comp. 0.00GB/s
   02/06/2008 13:51:08 CST comp. 95.82%, ratio 4.18%

- metadata
  - keep track of files that exist each backup
    - consider merits of storing as a list vs differential list?
    - notice when files move location
  - keep track of permissions and/or acl's where applicable
- backup the local system
  x dump://hostname/dir
    x hostname is only for the dir creation
    - fix the level>0 time issue
x backup samba shares accessable only via smbclient on a remote system
  x sshsmb://user@hostname/authname@remotesambahost/remotesharename
  - timestamp/auth info is xfered by execing a shell remotely, fix this!
- concurrency
 - 1st implement rough `maxconcurrence' per backup set
  - look at fetchitdave for inspiration
 - 2nd implement `maxconcurrence' per host and per backup set
 - setup level 0 backups in one queue, non lebel 0 in another, to
   permit new hosts etc to not keep level>0 backups from happening for days
- move filelist creation earlier, so .host_filesyst.level.filelist is moved
   with the rest instead of created after the move
 - perhaps even create the filelist via 'tee' and a fifo or somesuch
   so that reading the data happens as is it written to the disk, not
   reading it back causing more disk io

- error cleanup, don't leave unfinished backups lying around
  - use trap
- verify collections don't have more than one backup process running,
   so backups that take more than 24hrs will block other backups from
   running
  - almost makes some sense to have levels somewhat automatic, so one
    does not end up skipping level 1's for example because the night before's
    backup took too long
- backup-addhost / backup
 - implement 'df' output on the host to list partitions to potentially backup
 - permit copying the authorized_keys file into place and setting up the
   remote backup script

x show the time the backup is relative to, if not level 0
x permit using '-h 0' flag of dump
  (implemented by default, have to code more to make it optional)
- implement archiving to tape, e.g. ipmr
- update sshsmb to match smb regarding smbshare/smbdir
- write recover script to restore data

- ability to backup databases (PostgreSQL, MySQL, etc)

As spoken to a big chemical client:
 - the ability to set a parallel variable per host and per backup system,
   to backup multiple systems simultaneously; serially backing up systems
   when one system hangs (i.e. dump -L on FreeBSD) does not let things
   backup as expected
 - the ability to set a timeout on each backup process if it has not returned
   data within a timeout interval  
 - creating a 'recover' command to automate much of the data recovering phase
 - make the .filelist files a db of some sort instead of a text list to
   quickly process large volumes during recovery
 - create the .filelist `on the fly' while doing the backup; currently it
   requires a separate pass
 - compress via 'gzip' on the client instead of via ssh -C on the client,
   decompressing on the backup host, and then re-compressing on the backup     
   host
 - permit alternate compression mechanisms, lzma is best but chews cpu like
   a banshee  
 - integrate gpg for encrypted public private key backups
 - integrate openssl for passphrase encrypted backups
 - implement archiving to tape


- each system backed up can fit in one column, the stats output
  eventually shrink the output to columns
